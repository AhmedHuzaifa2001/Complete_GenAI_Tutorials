{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5525a56",
   "metadata": {},
   "source": [
    "##What is Stemming?\n",
    "\n",
    "Stemming is the process of reducing a word to its word stem, which may involve removing affixes, suffixes, or prefixes, or reducing it to the root of the word known as the lemma. This definition is sourced from Wikipedia. Stemming plays a crucial role in natural language understanding and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84816a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\", \"eats\", \"eaten\", \"writing\", \"writes\", \"programming\", \"programs\", \"history\", \"finally\", \"finalized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7123b29",
   "metadata": {},
   "source": [
    "### PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ce4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmingType = PorterStemmer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa0c4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating---------->eat\n",
      "eats---------->eat\n",
      "eaten---------->eaten\n",
      "writing---------->write\n",
      "writes---------->write\n",
      "programming---------->program\n",
      "programs---------->program\n",
      "history---------->histori\n",
      "finally---------->final\n",
      "finalized---------->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"---------->\" + stemmingType.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a684901d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratualt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Major disanvantages of stemming is that it may give not a \n",
    "# meaningful stem form for the original words\n",
    "stemmingType.stem(\"congratualtions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a68b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## solution is that we can use other stemming types\n",
    "from nltk.stem import RegexpStemmer\n",
    "st = RegexpStemmer('ing$|s$|e$|able$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5978530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Comput'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stem(\"Computing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e84cfdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Huzaifa'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stem(\"Huzaifaing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc280fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FAST'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stem(\"FASTing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52dfea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## snowball Stemmer\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51b35d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = SnowballStemmer(language = \"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9244a0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating------>eat\n",
      "eats------>eat\n",
      "eaten------>eaten\n",
      "writing------>write\n",
      "writes------>write\n",
      "programming------>program\n",
      "programs------>program\n",
      "history------>histori\n",
      "finally------>final\n",
      "finalized------>final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"------>\" + st.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "822bfdd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## comparing portstemmer and snowball stemmer\n",
    "stemmingType.stem(\"fairly\") , stemmingType.stem(\"sportingly\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4580f98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stem(\"fairly\") , st.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcf79c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## All these issues can be solved using a technique \n",
    "# called lemmatization  NEXT............\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
